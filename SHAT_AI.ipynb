{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5015406"
      },
      "source": [
        "# SHSAT AI: Question Generator and Explainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4df3142"
      },
      "source": [
        "# SHAT AI - Question Generation Model\n",
        "\n",
        "This notebook demonstrates how to use a fine-tuned GPT-based model to generate SHSAT-style math questions.\n",
        "The model is trained with a JSONL dataset and uses the `openai` Python API to interact with the fine-tuned model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b24d7380"
      },
      "source": [
        "## 1. Library Imports\n",
        "\n",
        "Import all required libraries for model interaction and file handling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55b8da61"
      },
      "source": [
        "## 2. Load Dataset\n",
        "\n",
        "Load and inspect the dataset used to fine-tune the GPT model. The dataset should be in `.jsonl` format, containing prompt-completion pairs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f82d5cd2"
      },
      "source": [
        "## 3. Model Configuration and Initialization\n",
        "\n",
        "Setup the OpenAI API key and specify the fine-tuned model name.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16068845"
      },
      "source": [
        "## 4. Generate SHSAT Math Questions\n",
        "\n",
        "Define a function to generate questions by passing a custom prompt to the fine-tuned model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5555ae15"
      },
      "source": [
        "## 5. Example Usage\n",
        "\n",
        "Use a sample prompt and display the model's response.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a76bdd8c"
      },
      "source": [
        "## 6. Current Limitations\n",
        "\n",
        "This model is trained on a limited dataset and may occasionally generate incorrect, unclear, or repetitive content.\n",
        "Future Improvements versions can benefit from a larger and more diverse dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01166257"
      },
      "source": [
        "## 7. Future Improvements Improvements\n",
        "\n",
        "- Expand dataset coverage for different SHSAT math topics.\n",
        "- Improve formatting and answer-explanation clarity.\n",
        "- Build a web interface to input prompts and get real-time questions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHiHwoVzyRyb",
        "outputId": "92e79f7c-2459-4c4c-8d66-461c6c5cfffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##File Uploading"
      ],
      "metadata": {
        "id": "T6AeELZzanGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgUgE9xpfiZk",
        "outputId": "b2056d12-c737-47de-e730-a7f58891d6a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.66.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHUtz3TMfoJ0",
        "outputId": "df8f44b6-e159-4a35-b3cd-9f4ca7247216"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Local Variables and Required Libaries"
      ],
      "metadata": {
        "id": "ODmK9UOojMxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "import time\n",
        "\n",
        "# Load environment variables once\n",
        "env_path = \"/content/drive/MyDrive/.env\"\n",
        "load_dotenv(dotenv_path=env_path)\n",
        "\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n"
      ],
      "metadata": {
        "id": "iomJoNEJfabR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset Uploaded"
      ],
      "metadata": {
        "id": "8KSteWCEjRyK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9eh-PvaRNRx",
        "outputId": "3a7c2c60-a838-4e60-c021-dc36319e2ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset uploaded successfully!\n"
          ]
        }
      ],
      "source": [
        "#file  uploaded\n",
        "file_path = \"/content/drive/MyDrive/shsat_finetune_data.jsonl\"\n",
        "if os.path.exists(file_path):\n",
        "    print(\"Dataset uploaded successfully!\")\n",
        "else:\n",
        "    print(\"Please upload the dataset manually in Colab.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAl-9wA6Vui2",
        "outputId": "f8c228fe-eb80-4211-e022-a49db91a0de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.67.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##File Upload\n"
      ],
      "metadata": {
        "id": "tGMNa044jViJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofq6DNfd_MqS",
        "outputId": "39fc7339-627d-4ae4-dc82-d4e848131d16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File uploaded:\n",
            "ID: file-PM2oP8NwSknofhChbYqi2n\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/shsat_finetune_data.jsonl\"\n",
        "\n",
        "with open(file_path, \"rb\") as file:\n",
        "    uploaded_file = client.files.create(\n",
        "        file=file,\n",
        "        purpose=\"fine-tune\"\n",
        "    )\n",
        "\n",
        "print(\"File uploaded:\")\n",
        "print(\"ID:\", uploaded_file.id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine-Tuning GPT-3.5 Turbo with Custom SHSAT Dataset\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jlhLTVCijoaf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfODSGbEZNOY",
        "outputId": "5b06a4fe-20b6-4f05-b5cc-8cbc6a36c058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded File ID: file-68DvUozqv97vGEgMkKR8i6\n",
            "Fine-tuning Job ID: ftjob-S1TUPNANOQubLwCRmzRo4LdL\n"
          ]
        }
      ],
      "source": [
        "\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "#file path\n",
        "file_path = \"/content/drive/MyDrive/shsat_finetune_data.jsonl\"\n",
        "\n",
        "#file opening for fine-tuning\n",
        "with open(file_path, \"rb\") as file:\n",
        "    upload_response = openai.files.create(\n",
        "        file=file,\n",
        "        purpose=\"fine-tune\"\n",
        "    )\n",
        "\n",
        "\n",
        "file_id = upload_response.id\n",
        "print(\"Uploaded File ID:\", file_id)\n",
        "\n",
        "# fine-tuning\n",
        "fine_tune_response = openai.fine_tuning.jobs.create(\n",
        "    training_file=file_id,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")\n",
        "\n",
        "\n",
        "fine_tune_id = fine_tune_response.id\n",
        "print(\"Fine-tuning Job ID:\", fine_tune_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checking Accessible Models from OpenAI API"
      ],
      "metadata": {
        "id": "17OC-wuOjtvB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlDWvv3DZk5A",
        "outputId": "62215604-ef67-4dd8-cd7c-71d128ee8a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available models: ['gpt-4o-mini-transcribe', 'gpt-4o-audio-preview-2024-12-17', 'dall-e-3', 'dall-e-2', 'gpt-4o-audio-preview-2024-10-01', 'omni-moderation-latest', 'omni-moderation-2024-09-26', 'gpt-4o-realtime-preview-2024-10-01', 'babbage-002', 'tts-1-hd-1106', 'text-embedding-3-large', 'gpt-4', 'gpt-4o-mini-2024-07-18', 'gpt-4o-2024-05-13', 'gpt-4o-realtime-preview-2024-12-17', 'tts-1-hd', 'gpt-4o-mini-audio-preview', 'gpt-4o-audio-preview', 'o1-preview-2024-09-12', 'gpt-4o-realtime-preview', 'gpt-3.5-turbo-instruct-0914', 'gpt-4o-mini-search-preview', 'tts-1-1106', 'davinci-002', 'gpt-3.5-turbo-1106', 'gpt-4o-search-preview', 'gpt-4-turbo', 'gpt-3.5-turbo-instruct', 'gpt-3.5-turbo', 'gpt-4-turbo-preview', 'gpt-4o-mini-search-preview-2025-03-11', 'gpt-4o-mini-realtime-preview', 'chatgpt-4o-latest', 'whisper-1', 'gpt-3.5-turbo-0125', 'gpt-4-turbo-2024-04-09', 'gpt-3.5-turbo-16k', 'gpt-4o', 'gpt-4o-mini-realtime-preview-2024-12-17', 'gpt-4-1106-preview', 'text-embedding-ada-002', 'o1-preview', 'gpt-4-0613', 'gpt-4.5-preview', 'gpt-4.5-preview-2025-02-27', 'gpt-4o-search-preview-2025-03-11', 'gpt-4o-2024-11-20', 'tts-1', 'gpt-4o-mini-tts', 'text-embedding-3-small', 'gpt-4-0125-preview', 'gpt-4o-transcribe', 'gpt-4o-mini', 'gpt-4o-2024-08-06', 'o1-mini', 'gpt-4o-mini-audio-preview-2024-12-17', 'o1-mini-2024-09-12', 'ft:gpt-3.5-turbo-0125:personal::BDKSewPF:ckpt-step-283', 'ft:gpt-3.5-turbo-0125:personal::BDKSeSTQ:ckpt-step-566', 'ft:gpt-3.5-turbo-0125:personal::BDKSf2Cg', 'ft:gpt-3.5-turbo-0125:personal::BDKTCrvJ:ckpt-step-283', 'ft:gpt-3.5-turbo-0125:personal::BDKTDWhW:ckpt-step-566', 'ft:gpt-3.5-turbo-0125:personal::BDKTDVXe', 'ft:gpt-3.5-turbo-0125:personal::BDKqeRqa:ckpt-step-283', 'ft:gpt-3.5-turbo-0125:personal::BDKqeX2H:ckpt-step-566', 'ft:gpt-3.5-turbo-0125:personal::BDKqehOH', 'ft:gpt-3.5-turbo-0125:personal::BDDQF05J', 'ft:gpt-3.5-turbo-0125:personal::BDDNrAp3:ckpt-step-283', 'ft:gpt-3.5-turbo-0125:personal::BDDNrRNc:ckpt-step-566', 'ft:gpt-3.5-turbo-0125:personal::BDDNrtlp', 'ft:gpt-3.5-turbo-0125:personal::BDDQFp9u:ckpt-step-283', 'ft:gpt-3.5-turbo-0125:personal::BDDQFxrg:ckpt-step-566']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "models = openai.models.list()\n",
        "\n",
        "model_ids = [model.id for model in models.data]\n",
        "\n",
        "# available models\n",
        "print(\"Available models:\", model_ids)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine-Tune Execution Pipeline"
      ],
      "metadata": {
        "id": "w_3Ft6cDlWSb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnIcWj8ca7x3",
        "outputId": "78397604-e713-4289-b8a1-67a14528b073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File uploaded. File ID: file-ThqD1sD1ovxaZpfhpVhFQD\n",
            "Fine-tuning started. Job ID: {job_id}\n",
            "📡 Status: validating_files\n",
            "📡 Status: validating_files\n",
            "📡 Status: validating_files\n",
            "📡 Status: validating_files\n",
            "📡 Status: validating_files\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: running\n",
            "📡 Status: succeeded\n",
            "\n",
            " Fine-tuned model ready: {job.fine_tuned_model}\n"
          ]
        }
      ],
      "source": [
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Upload JSONL\n",
        "upload_response = client.files.create(\n",
        "    file=open(\"/content/drive/MyDrive/shsat_finetune_data.jsonl\", \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "file_id = upload_response.id\n",
        "print(f\"File uploaded. File ID: {file_id}\")\n",
        "\n",
        "#  fine-tuning job started\n",
        "fine_tune_response = client.fine_tuning.jobs.create(\n",
        "    training_file=file_id,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")\n",
        "job_id = fine_tune_response.id\n",
        "print(\"Fine-tuning started. Job ID: {job_id}\")\n",
        "\n",
        "# Monitoring job status\n",
        "while True:\n",
        "    job = client.fine_tuning.jobs.retrieve(job_id)\n",
        "    print(f\"📡 Status: {job.status}\")\n",
        "    if job.status in [\"succeeded\", \"failed\", \"cancelled\"]:\n",
        "        break\n",
        "    time.sleep(15)\n",
        "\n",
        "# successful get the model ID\n",
        "if job.status == \"succeeded\":\n",
        "    print(\"\\n Fine-tuned model ready: {job.fine_tuned_model}\")\n",
        "else:\n",
        "    print(\"\\n Fine-tuning failed. Check your dataset and try again.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Automated Math Question Creation"
      ],
      "metadata": {
        "id": "XQQem9I8kNe7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctf-cA7mQPCl",
        "outputId": "d240b2b5-f9ce-4cf6-9621-a783be78eb82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. What is the solution to the equation 3x + 5 = 17?\n",
            "Answer: 4.0\n",
            "2. What is the solution to the equation 8x - 3 = 17?\n",
            "Answer: 2.5\n",
            "3. What is the solution to the equation 4*x=20?\n",
            "Answer: 5.0\n",
            "4. What is the solution to the equation 9*x+3=15?\n",
            "Answer: 1.0\n",
            "5. What is the solution to the equation 5*x-8=7?\n",
            "Answer: 3.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"ft:gpt-3.5-turbo-0125:personal::BDKqehOH\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Generate 5 math question by algebra and give answer students.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
